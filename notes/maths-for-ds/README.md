# Mathematics for Data Science - IITM Qualifier

## Table of Contents
1. [Calculus Fundamentals](#calculus-fundamentals)
2. [Linear Algebra Basics](#linear-algebra-basics)  
3. [Probability Theory](#probability-theory)
4. [Optimization Methods](#optimization-methods)
5. [Practice Quizzes](#practice-quizzes)

---

## Calculus Fundamentals

### 1.1 Limits and Continuity

#### Definition of Limit
The limit of a function f(x) as x approaches a value 'a' is:

lim(xâ†’a) f(x) = L

This means f(x) gets arbitrarily close to L as x gets arbitrarily close to a.

#### Properties of Limits
- **Sum Rule**: lim(xâ†’a) [f(x) + g(x)] = lim(xâ†’a) f(x) + lim(xâ†’a) g(x)
- **Product Rule**: lim(xâ†’a) [f(x) Â· g(x)] = lim(xâ†’a) f(x) Â· lim(xâ†’a) g(x)
- **Quotient Rule**: lim(xâ†’a) [f(x)/g(x)] = lim(xâ†’a) f(x) / lim(xâ†’a) g(x), provided lim(xâ†’a) g(x) â‰  0

#### Example Problem
Find lim(xâ†’2) (xÂ² - 4)/(x - 2)

**Solution:**
```
lim(xâ†’2) (xÂ² - 4)/(x - 2) = lim(xâ†’2) (x + 2)(x - 2)/(x - 2)
                           = lim(xâ†’2) (x + 2)
                           = 2 + 2 = 4
```

### 1.2 Derivatives

#### Definition
The derivative of f(x) at point x is:
f'(x) = lim(hâ†’0) [f(x + h) - f(x)]/h

#### Basic Derivatives
- d/dx (c) = 0 (constant rule)
- d/dx (x^n) = nx^(n-1) (power rule)
- d/dx (e^x) = e^x
- d/dx (ln x) = 1/x
- d/dx (sin x) = cos x
- d/dx (cos x) = -sin x

#### Chain Rule
If y = f(g(x)), then dy/dx = f'(g(x)) Â· g'(x)

#### Applications in Data Science
- **Gradient Descent**: Uses derivatives to minimize cost functions
- **Optimization**: Finding maximum/minimum values of functions
- **Rate of Change**: Understanding how variables change with respect to each other

---

## Linear Algebra Basics

### 2.1 Vectors

#### Vector Definition
A vector is an ordered list of numbers: **v** = [vâ‚, vâ‚‚, ..., vâ‚™]

#### Vector Operations
- **Addition**: **u** + **v** = [uâ‚ + vâ‚, uâ‚‚ + vâ‚‚, ..., uâ‚™ + vâ‚™]
- **Scalar Multiplication**: c**v** = [cvâ‚, cvâ‚‚, ..., cvâ‚™]
- **Dot Product**: **u** Â· **v** = uâ‚vâ‚ + uâ‚‚vâ‚‚ + ... + uâ‚™vâ‚™

#### Example
Given **u** = [2, 3, 1] and **v** = [1, -2, 4]:
- **u** + **v** = [3, 1, 5]
- 2**u** = [4, 6, 2]
- **u** Â· **v** = 2(1) + 3(-2) + 1(4) = 2 - 6 + 4 = 0

### 2.2 Matrices

#### Matrix Operations
- **Addition**: [A + B]áµ¢â±¼ = Aáµ¢â±¼ + Báµ¢â±¼
- **Multiplication**: [AB]áµ¢â±¼ = Î£â‚– Aáµ¢â‚–Bâ‚–â±¼
- **Transpose**: [A^T]áµ¢â±¼ = Aâ±¼áµ¢

#### Applications in Data Science
- **Data Representation**: Each row represents a data point, columns represent features
- **Transformations**: Rotating, scaling, and translating data
- **Dimensionality Reduction**: PCA uses eigenvalues and eigenvectors

---

## Probability Theory

### 3.1 Basic Probability

#### Sample Space and Events
- **Sample Space (Î©)**: Set of all possible outcomes
- **Event (A)**: Subset of the sample space
- **Probability**: P(A) = Number of favorable outcomes / Total number of outcomes

#### Properties
- 0 â‰¤ P(A) â‰¤ 1
- P(Î©) = 1
- P(âˆ…) = 0
- P(A âˆª B) = P(A) + P(B) - P(A âˆ© B)

### 3.2 Conditional Probability

#### Definition
P(A|B) = P(A âˆ© B) / P(B), provided P(B) > 0

#### Bayes' Theorem
P(A|B) = P(B|A) Â· P(A) / P(B)

#### Example: Medical Diagnosis
- Disease prevalence: P(D) = 0.01
- Test sensitivity: P(+|D) = 0.99
- Test specificity: P(-|DÌ„) = 0.95

Find P(D|+):
```
P(D|+) = P(+|D) Â· P(D) / P(+)
where P(+) = P(+|D)Â·P(D) + P(+|DÌ„)Â·P(DÌ„)
         = 0.99Ã—0.01 + 0.05Ã—0.99 = 0.0594
Therefore: P(D|+) = (0.99Ã—0.01) / 0.0594 â‰ˆ 0.167
```

### 3.3 Common Distributions

#### Normal Distribution
- **PDF**: f(x) = (1/Ïƒâˆš(2Ï€)) Â· e^(-(x-Î¼)Â²/(2ÏƒÂ²))
- **Parameters**: Î¼ (mean), ÏƒÂ² (variance)
- **68-95-99.7 Rule**: 68% within 1Ïƒ, 95% within 2Ïƒ, 99.7% within 3Ïƒ

#### Binomial Distribution
- **PMF**: P(X = k) = C(n,k) Â· p^k Â· (1-p)^(n-k)
- **Parameters**: n (trials), p (success probability)
- **Mean**: Î¼ = np
- **Variance**: ÏƒÂ² = np(1-p)

---

## Optimization Methods

### 4.1 Single Variable Optimization

#### Finding Critical Points
1. Find f'(x) = 0
2. Check second derivative: f''(x) > 0 (minimum), f''(x) < 0 (maximum)

#### Example
Minimize f(x) = xÂ² - 4x + 5
```
f'(x) = 2x - 4 = 0
x = 2
f''(x) = 2 > 0, so x = 2 is a minimum
f(2) = 4 - 8 + 5 = 1
```

### 4.2 Multivariable Optimization

#### Gradient Vector
For f(x, y): âˆ‡f = [âˆ‚f/âˆ‚x, âˆ‚f/âˆ‚y]

#### Critical Points
Set âˆ‡f = 0 and solve the system of equations.

#### Applications
- **Machine Learning**: Minimizing cost functions
- **Statistics**: Maximum likelihood estimation
- **Economics**: Utility maximization

---

## Practice Quizzes

### Quiz 1: Limits and Derivatives
1. Find lim(xâ†’0) sin(x)/x
2. Find the derivative of f(x) = xÂ³ + 2xÂ² - 5x + 1
3. Use the chain rule to find d/dx[sin(xÂ²)]

### Quiz 2: Linear Algebra
1. Calculate the dot product of [1, 2, 3] and [4, -1, 2]
2. Find the transpose of matrix [[1, 2], [3, 4]]
3. Multiply matrices [[1, 2], [3, 4]] and [[2], [1]]

### Quiz 3: Probability
1. If P(A) = 0.3 and P(B) = 0.4, and A and B are independent, find P(A âˆ© B)
2. A coin is flipped 5 times. What's the probability of getting exactly 3 heads?
3. Apply Bayes' theorem to find P(A|B) given P(B|A) = 0.8, P(A) = 0.3, P(B) = 0.5

### Solutions
**Quiz 1:**
1. lim(xâ†’0) sin(x)/x = 1 (standard limit)
2. f'(x) = 3xÂ² + 4x - 5
3. d/dx[sin(xÂ²)] = cos(xÂ²) Â· 2x = 2x cos(xÂ²)

**Quiz 2:**
1. [1, 2, 3] Â· [4, -1, 2] = 1(4) + 2(-1) + 3(2) = 4 - 2 + 6 = 8
2. [[1, 2], [3, 4]]^T = [[1, 3], [2, 4]]
3. [[1, 2], [3, 4]] Ã— [[2], [1]] = [[4], [10]]

**Quiz 3:**
1. P(A âˆ© B) = P(A) Ã— P(B) = 0.3 Ã— 0.4 = 0.12
2. P(X = 3) = C(5,3) Ã— (0.5)Â³ Ã— (0.5)Â² = 10 Ã— 0.125 Ã— 0.25 = 0.3125
3. P(A|B) = (0.8 Ã— 0.3) / 0.5 = 0.24 / 0.5 = 0.48

---

## Quick Reference

### Essential Formulas
- **Derivative of e^(ax)**: ae^(ax)
- **Derivative of ln(ax)**: a/x
- **Integration by parts**: âˆ«u dv = uv - âˆ«v du
- **Normal distribution mean**: Î¼
- **Normal distribution variance**: ÏƒÂ²
- **Standard error**: Ïƒ/âˆšn

### Key Concepts for Exams
1. **L'HÃ´pital's Rule**: For indeterminate forms 0/0 or âˆ/âˆ
2. **Matrix inverse**: Aâ»Â¹ exists if det(A) â‰  0
3. **Independence**: P(A âˆ© B) = P(A) Ã— P(B)
4. **Central Limit Theorem**: Sample means approach normal distribution

---

*Next: Advanced topics in multivariate calculus and matrix decomposition*

**ğŸ“ Study Tips:**
- Practice daily problems from each section
- Focus on understanding concepts, not just memorizing formulas  
- Use graphing tools to visualize functions and their derivatives
- Connect mathematical concepts to data science applications